{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "d2kWWhbV4sE9",
        "outputId": "1b1473d6-9b94-4d56-a12e-c35afd6ba612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Date and Time: 03:37 PM IST, Monday, August 18, 2025\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 12 fields in line 24038, saw 13\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-323179654.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Load CSV data for Madhya Pradesh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Agri-multicrop.csv'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust path if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'State Name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Madhya Pradesh'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Filter for Madhya Pradesh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Reported Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Reported Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 12 fields in line 24038, saw 13\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import os\n",
        "\n",
        "# Current date and time (updated to current system time)\n",
        "current_datetime = \"03:37 PM IST, Monday, August 18, 2025\"\n",
        "print(f\"Current Date and Time: {current_datetime}\")\n",
        "\n",
        "# Configure Gemini 1.5 Flash API (replace with your actual API key)\n",
        "genai.configure(api_key='AIzaSyD0_1BDN3m-3YK0NU1zYU71i-egFoWEJCs')\n",
        "\n",
        "# Function to get coordinates\n",
        "def get_coordinates(state, district, market):\n",
        "    try:\n",
        "        address = f\"{market}, {district}, {state}, India\"\n",
        "        url = f\"https://nominatim.openstreetmap.org/search?format=json&q={address}\"\n",
        "        response = requests.get(url, headers={'User-Agent': 'MyApp/1.0 (myemail@example.com)'}, timeout=5)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        if data:\n",
        "            return float(data[0]['lat']), float(data[0]['lon'])\n",
        "    except Exception:\n",
        "        return 0.0, 0.0\n",
        "    return 0.0, 0.0\n",
        "\n",
        "# Load CSV data for Madhya Pradesh\n",
        "df = pd.read_csv('/content/Agri-multicrop.csv')  # Adjust path if needed\n",
        "df = df[df['State Name'] == 'Madhya Pradesh']  # Filter for Madhya Pradesh\n",
        "df['Reported Date'] = pd.to_datetime(df['Reported Date'], errors='coerce')\n",
        "df = df.sort_values('Reported Date')\n",
        "\n",
        "# Dynamically get crop types from 'Type' column\n",
        "crops = df['Type'].dropna().unique().tolist()\n",
        "print(\"Available Crops in Madhya Pradesh:\", crops)\n",
        "\n",
        "# Extract unique markets and get coordinates\n",
        "unique_markets = df[['District Name', 'Market Name']].drop_duplicates()\n",
        "mandis = []\n",
        "for _, row in unique_markets.iterrows():\n",
        "    district = row['District Name']\n",
        "    market = row['Market Name']\n",
        "    lat, lon = get_coordinates('Madhya Pradesh', district, market)\n",
        "    if lat != 0.0 and lon != 0.0:\n",
        "        mandis.append((market, lat, lon))\n",
        "    time.sleep(1)\n",
        "\n",
        "# Coordinates array\n",
        "coords = np.array([[lat, lon] for _, lat, lon in mandis])\n",
        "\n",
        "# Vendor location near Alirajpur\n",
        "vendor_location = np.array([[22.1633, 74.5353]])\n",
        "\n",
        "# KNN for nearest market (K=1)\n",
        "k = 1\n",
        "if len(coords) >= k:\n",
        "    neigh = NearestNeighbors(n_neighbors=k)\n",
        "    neigh.fit(coords)\n",
        "    distances, indices = neigh.kneighbors(vendor_location)\n",
        "    nearest_idx = indices[0][0]\n",
        "    nearest_market = mandis[nearest_idx][0]\n",
        "    nearest_dist = distances[0][0]\n",
        "    print(f\"Nearest Market to Alirajpur: {nearest_market} (Distance: {nearest_dist:.4f} degrees)\")\n",
        "else:\n",
        "    print(\"No valid markets found.\")\n",
        "    exit()\n",
        "\n",
        "# Dynamically get base market (first market in dataset)\n",
        "base_market = df['Market Name'].iloc[0]\n",
        "print(f\"Base Market: {base_market}\")\n",
        "\n",
        "# Function to train or load LSTM and predict for a crop in a market\n",
        "def forecast_price(df_market, crop, seq_length=2, epochs=10, force_retrain=False):\n",
        "    model_path = f'/content/lstm_model_{crop}_{df_market[\"Market Name\"].iloc[0]}.h5'\n",
        "\n",
        "    # Check if model exists and load if not forcing retrain\n",
        "    if os.path.exists(model_path) and not force_retrain:\n",
        "        model = load_model(model_path)\n",
        "        scaler = MinMaxScaler()  # Load scaler separately if saved; here, recreate for simplicity\n",
        "        print(f\"Loaded pre-trained model for {crop} in {df_market['Market Name'].iloc[0]}\")\n",
        "    else:\n",
        "        df_crop = df_market[df_market['Type'] == crop]\n",
        "        if len(df_crop) < seq_length + 1:\n",
        "            print(f\"Insufficient data for {crop} in {df_market['Market Name'].iloc[0]}\")\n",
        "            return None\n",
        "\n",
        "        prices = df_crop['Modal Price (Rs./Quintal)'].values.reshape(-1, 1)\n",
        "        scaler = MinMaxScaler()\n",
        "        prices_scaled = scaler.fit_transform(prices)\n",
        "\n",
        "        X, y = [], []\n",
        "        for i in range(len(prices_scaled) - seq_length):\n",
        "            X.append(prices_scaled[i:i + seq_length])\n",
        "            y.append(prices_scaled[i + seq_length])\n",
        "        X, y = np.array(X), np.array(y)\n",
        "        X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "        train_size = int(len(X) * 0.8)\n",
        "        X_train, X_test = X[:train_size], X[train_size:]\n",
        "        y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "        model = Sequential([\n",
        "            LSTM(50, activation='relu', return_sequences=True, input_shape=(seq_length, 1)),\n",
        "            Dropout(0.2),\n",
        "            LSTM(50, activation='relu'),\n",
        "            Dropout(0.2),\n",
        "            Dense(1)\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "        model.fit(X_train, y_train, epochs=epochs, batch_size=1, validation_split=0.2, verbose=1)\n",
        "\n",
        "        test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "        print(f'{crop} Test MAE in {df_market[\"Market Name\"].iloc[0]}: ₹{test_mae * (prices.max() - prices.min()):.2f}/quintal')\n",
        "\n",
        "        # Save the model\n",
        "        model.save(model_path)\n",
        "        print(f\"Saved model for {crop} in {df_market['Market Name'].iloc[0]} to {model_path}\")\n",
        "\n",
        "    # Predict\n",
        "    last_sequence = prices_scaled[-seq_length:].reshape(1, seq_length, 1)\n",
        "    predicted_scaled = model.predict(last_sequence, verbose=0)\n",
        "    predicted_price = scaler.inverse_transform(predicted_scaled)[0][0]\n",
        "    return predicted_price\n",
        "\n",
        "# Filter data for base market and nearest market\n",
        "df_base = df[df['Market Name'].str.contains(base_market, case=False)]\n",
        "df_nearest = df[df['Market Name'].str.contains(nearest_market, case=False)]\n",
        "\n",
        "# User input for crop selection, action, and retrain option\n",
        "print(f\"\\nCurrent Date and Time: {current_datetime}\")\n",
        "print(\"Available Crops in Madhya Pradesh:\", crops)\n",
        "selected_crop = input(\"Select a crop (e.g., Wheat, Soybean, Gram, Maize, Cotton): \").strip().capitalize()\n",
        "while selected_crop not in crops:\n",
        "    print(\"Invalid crop. Choose from:\", crops)\n",
        "    selected_crop = input(\"Select a crop: \").strip().capitalize()\n",
        "\n",
        "action = input(\"Choose action (1 for Price Prediction, 2 for LLM Offer): \").strip()\n",
        "if action not in ['1', '2']:\n",
        "    print(\"Invalid action. Defaulting to Price Prediction.\")\n",
        "    action = '1'\n",
        "\n",
        "retrain = input(\"Force retrain models? (yes/no): \").strip().lower() == 'yes'\n",
        "\n",
        "# Price Forecasting\n",
        "if action == '1':\n",
        "    print(f\"\\nPrice Forecasts for {selected_crop} as of {current_datetime}:\")\n",
        "    if selected_crop in df_base['Type'].values:\n",
        "        base_predicted = forecast_price(df_base, selected_crop, force_retrain=retrain)\n",
        "        if base_predicted is not None:\n",
        "            print(f'{selected_crop} Predicted Price in {base_market}: ₹{base_predicted:.2f}/quintal')\n",
        "    if selected_crop in df_nearest['Type'].values:\n",
        "        nearest_predicted = forecast_price(df_nearest, selected_crop, force_retrain=retrain)\n",
        "        if nearest_predicted is not None:\n",
        "            print(f'{selected_crop} Predicted Price in {nearest_market}: ₹{nearest_predicted:.2f}/quintal')\n",
        "\n",
        "# LLM Implementation for Offer/Comparison\n",
        "elif action == '2':\n",
        "    gemini_model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "    # Use pre-trained models for predictions\n",
        "    base_predicted = forecast_price(df_base, selected_crop, force_retrain=retrain) if selected_crop in df_base['Type'].values else None\n",
        "    nearest_predicted = forecast_price(df_nearest, selected_crop, force_retrain=retrain) if selected_crop in df_nearest['Type'].values else None\n",
        "\n",
        "    base_price = f\"₹{base_predicted:.2f}/quintal\" if base_predicted else \"Not available\"\n",
        "    nearest_price = f\"₹{nearest_predicted:.2f}/quintal\" if nearest_predicted else \"Not available\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Generate a tailored, multilingual offer (English and Hindi) for a farmer in Madhya Pradesh to sell {selected_crop} to a vendor.\n",
        "    Base Market ({base_market}) Price: {base_price} as of {current_datetime}.\n",
        "    Nearest Market ({nearest_market}) Price: {nearest_price} as of {current_datetime}.\n",
        "    Highlight the better deal (lower price or similar availability) and persuade the farmer to sell at the nearest market.\n",
        "    Make it friendly, actionable, and include the current date and time.\n",
        "    \"\"\"\n",
        "    response = gemini_model.generate_content(prompt)\n",
        "    offer_message = response.text\n",
        "    print(f\"\\nLLM-Generated Offer (via Gemini 1.5 Flash) as of {current_datetime}:\\n\")\n",
        "    print(offer_message)"
      ]
    }
  ]
}